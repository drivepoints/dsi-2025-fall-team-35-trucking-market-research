{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "80189803-0a62-45f5-b161-042b590c5a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== FARS assign fault + US DOT filter + census merge + PARQUET export =====\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "#Get data ready\n",
    "def _clean_usdot(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Get rid of leading 0s and make USDOT a string for merging purposes\n",
    "    \"\"\"\n",
    "    s = s.astype(\"string\").str.strip().str.replace(r\"^\\s*0+(?=\\d)\", \"\", regex=True)\n",
    "    return s.mask(s.isin([\"\", \"nan\", \"<NA>\"]))\n",
    "\n",
    "def _num(d: pd.DataFrame, col: str) -> pd.Series:\n",
    "    return pd.to_numeric(d[col], errors=\"coerce\") if col in d.columns else pd.Series(np.nan, index=d.index)\n",
    "\n",
    "def load_fars_vehicle(files_with_years: List[Tuple[str, int]]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load multiple FARS vehicle CSVs and append a YEAR column\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    for path, year in files_with_years:\n",
    "        df = pd.read_csv(path, low_memory=False)\n",
    "        df.columns = pd.Index([str(c).strip().upper() for c in df.columns])\n",
    "        df[\"YEAR\"] = int(year)\n",
    "        frames.append(df)\n",
    "    return pd.concat(frames, ignore_index=True)\n",
    "\n",
    "# Determining accident fault\n",
    "def compute_fault(df: pd.DataFrame, source_label: str = \"FARS\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute a simple fault score and binary likely-at-fault flag for each vehicle\n",
    "    Likely-at-fault flag assigned to vehicles with a fault score of at least 2\n",
    "    Numbered values are taken from the FARS codebook and represent factors that likely indicate fault in the accident\n",
    "    \"\"\"\n",
    "    d = df.copy()\n",
    "    d.columns = pd.Index([str(c).strip().upper() for c in d.columns])\n",
    "    d[\"SOURCE\"] = source_label\n",
    "\n",
    "    acc  = _num(d, \"ACC_TYPE\")\n",
    "    pc1  = _num(d, \"P_CRASH1\")\n",
    "    pc2  = _num(d, \"P_CRASH2\")\n",
    "    pc3  = _num(d, \"P_CRASH3\")\n",
    "    pc4  = _num(d, \"P_CRASH4\")\n",
    "    pc5  = _num(d, \"P_CRASH5\")\n",
    "    spd  = _num(d, \"SPEEDREL\")\n",
    "    drink= _num(d, \"DR_DRINK\")\n",
    "\n",
    "    #Vehicle coded as having struck something (likely at fault)\n",
    "    striking_codes = set(range(1,11)) | set(range(20,35)) | {36,38,40,44,45,46,47,64,65} | set(range(68,86)) | {92}\n",
    "\n",
    "    #Vehicle coded as being struck by something (less likely at fault)\n",
    "    struck_codes   = {35,37,39,41,55,57,59,61,87,89}\n",
    "\n",
    "    self_induced   = {6,10,11,12,13,14,18}\n",
    "    other_encroach = set(range(60,66)) | {66,67,70,71,72,73,74,78}\n",
    "    risky_move     = {6,13,14,15,16}\n",
    "    loss_control   = {2,3,4,5,7}\n",
    "    off_road       = {4,5}\n",
    "    no_avoid       = {1}\n",
    "\n",
    "    EV_STRIKING  = acc.isin(striking_codes)\n",
    "    EV_STRUCK    = acc.isin(struck_codes)\n",
    "    EV_SELF_HAZ  = pc2.isin(self_induced) | pc4.isin(loss_control) | pc5.isin(off_road) | pc1.isin(risky_move)\n",
    "    EV_OTHER_HAZ = pc2.isin(other_encroach)\n",
    "    EV_NO_AVOID  = pc3.isin(no_avoid)\n",
    "    FAULT_AVOID  = (acc.isin(struck_codes) & pc2.isin(self_induced))\n",
    "    EV_SPEED     = (~spd.isin([0,8,9]))\n",
    "    EV_DRINK     = (drink == 1)\n",
    "\n",
    "    #Weighted scores based on likelihood of direct cause of accident vs incidental causes of accident\n",
    "    fault_score = (\n",
    "        3*(EV_STRIKING | EV_SELF_HAZ | FAULT_AVOID).astype(int)\n",
    "        + 2*EV_NO_AVOID.astype(int)\n",
    "        - 3*(EV_STRUCK | EV_OTHER_HAZ).astype(int)\n",
    "        + 2*EV_SPEED.astype(int)\n",
    "        + 1*EV_DRINK.astype(int)\n",
    "    )\n",
    "    d[\"FAULT_SCORE\"] = fault_score\n",
    "    d[\"LIKELY_AT_FAULT\"] = np.select([fault_score >= 2, fault_score <= -2], [1, 0], default=np.nan)\n",
    "    return d\n",
    "\n",
    "def filter_trucking_with_usdot(df: pd.DataFrame,\n",
    "                               mcarr_flag_col=\"MCARR_I1\", usdot_col=\"MCARR_I2\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters FARS vehicles to those with MCARR_I1 == 57 with a valid USDOT number\n",
    "    \"\"\"\n",
    "    d = df.copy()\n",
    "    d.columns = pd.Index([str(c).strip().upper() for c in d.columns])\n",
    "    d[mcarr_flag_col] = pd.to_numeric(d[mcarr_flag_col], errors=\"coerce\")\n",
    "    d[usdot_col] = _clean_usdot(d[usdot_col])\n",
    "    return d[(d[mcarr_flag_col] == 57) & d[usdot_col].notna()].copy()\n",
    "\n",
    "# Merge FARS data to larger trucking census data\n",
    "def merge_census_with_fars(census_csv: str, vehicles_df: pd.DataFrame,\n",
    "                           census_col=\"DOT_NUMBER\", veh_usdot_col=\"MCARR_I2\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Keep ALL census rows and attach any matching FARS rows (zero, one, or many).\n",
    "    Census is the primary table.\n",
    "    \"\"\"\n",
    "    # Prep FARS\n",
    "    v = vehicles_df.copy()\n",
    "    v.columns = pd.Index([str(c).strip().upper() for c in v.columns])\n",
    "    v[veh_usdot_col] = _clean_usdot(v[veh_usdot_col])\n",
    "\n",
    "    # Load Census\n",
    "    census = pd.read_csv(census_csv, low_memory=False)\n",
    "    census.columns = pd.Index([str(c).strip().upper() for c in census.columns])\n",
    "    census[census_col] = _clean_usdot(census[census_col])\n",
    "\n",
    "    # Left join FROM census TO FARS\n",
    "    merged = census.merge(\n",
    "        v,\n",
    "        left_on=census_col,\n",
    "        right_on=veh_usdot_col,\n",
    "        how=\"left\",\n",
    "        validate=\"1:m\",\n",
    "        suffixes=(\"\", \"_FARS\"),\n",
    "        indicator=True\n",
    "    )\n",
    "\n",
    "    # Diagnostics\n",
    "    match_rate = (merged[\"_merge\"] == \"both\").mean()\n",
    "    print(f\"Census rows: {len(census):,}\")\n",
    "    print(f\"Row-level match rate (after expansion by FARS vehicles): {match_rate:.1%}\")\n",
    "    print(f\"Census rows with â‰¥1 FARS match: \"\n",
    "          f\"{merged.groupby(census_col)['_merge'].first().eq('both').mean():.1%}\")\n",
    "\n",
    "    merged = merged.drop(columns=[\"_merge\"])\n",
    "    return merged\n",
    "\n",
    "# Check correlation on vehicles labelled \"1\" in FARS with fault scoring\n",
    "\n",
    "def vehicle1_fault_summary(scored_df: pd.DataFrame) -> None:\n",
    "    d = scored_df.copy()\n",
    "    d[\"VEH_NO\"] = pd.to_numeric(d.get(\"VEH_NO\"), errors=\"coerce\")\n",
    "    d[\"FAULT_SCORE\"] = pd.to_numeric(d.get(\"FAULT_SCORE\"), errors=\"coerce\")\n",
    "    d[\"LIKELY_AT_FAULT\"] = pd.to_numeric(d.get(\"LIKELY_AT_FAULT\"), errors=\"coerce\")\n",
    "    d[\"IsVeh1\"] = np.where(d[\"VEH_NO\"] == 1, \"Vehicle 1\", \"Other Vehicles\")\n",
    "    summary = (\n",
    "        d.groupby(\"IsVeh1\")[[\"FAULT_SCORE\", \"LIKELY_AT_FAULT\"]]\n",
    "         .agg([\"mean\",\"count\"])\n",
    "    )\n",
    "    corr = (\n",
    "        d.assign(IsVeh1_flag=(d[\"VEH_NO\"] == 1).astype(int))[[\"IsVeh1_flag\",\"FAULT_SCORE\"]]\n",
    "         .corr().iloc[0,1]\n",
    "    )\n",
    "    print(\"\\n--- Vehicle 1 vs Others (FULL sample) ---\")\n",
    "    print(summary)\n",
    "    print(f\"\\nCorrelation between Vehicle 1 and FAULT_SCORE: {corr:.3f}\")\n",
    "\n",
    "# Pipeline for everything\n",
    "def run_fars_pipeline(fars_files: List[Tuple[str, int]], census_csv: str,\n",
    "                      out_scored=\"fars_scored.parquet\",\n",
    "                      out_trucking=\"fars_trucking_usdot.parquet\",\n",
    "                      out_merged=\"census_with_fars.parquet\"):\n",
    "    \"\"\"\n",
    "    Full pipeline: load FARS, score, filter for USDOT numbers, merge with census, export\n",
    "    \"\"\"\n",
    "    vehicles_all = load_fars_vehicle(fars_files)\n",
    "    print(f\"Combined FARS vehicle records: {len(vehicles_all):,}\")\n",
    "\n",
    "    vehicles_scored = compute_fault(vehicles_all, source_label=\"FARS\")\n",
    "    vehicle1_fault_summary(vehicles_scored)\n",
    "\n",
    "    trucking = filter_trucking_with_usdot(vehicles_scored, \"MCARR_I1\", \"MCARR_I2\")\n",
    "    print(f\"\\nTrucking subset (MCARR_I1==57 & USDOT present): {len(trucking):,}\")\n",
    "    print(f\"Unique DOTs in trucking subset: {trucking['MCARR_I2'].nunique():,}\")\n",
    "\n",
    "    merged = merge_census_with_fars(census_csv, trucking, \"DOT_NUMBER\", \"MCARR_I2\")\n",
    "    print(f\"\\nMerged census (kept all rows): {len(merged):,} total rows; unique DOTs: {merged['DOT_NUMBER'].nunique():,}\")\n",
    "\n",
    "    # Export as Parquet\n",
    "    vehicles_scored.to_parquet(out_scored, index=False)\n",
    "    trucking.to_parquet(out_trucking, index=False)\n",
    "    merged.to_parquet(out_merged, index=False)\n",
    "\n",
    "    print(f\"\\nSaved Parquet files:\\n  {out_scored}\\n  {out_trucking}\\n  {out_merged}\")\n",
    "    return vehicles_scored, trucking, merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "74aef00b-1aa4-48f0-b313-7549259f5f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined FARS vehicle records: 235,438\n",
      "\n",
      "--- Vehicle 1 vs Others (FULL sample) ---\n",
      "               FAULT_SCORE         LIKELY_AT_FAULT        \n",
      "                      mean   count            mean   count\n",
      "IsVeh1                                                    \n",
      "Other Vehicles    0.471990   82862        0.604366   49652\n",
      "Vehicle 1         2.893201  152576        0.955218  118687\n",
      "\n",
      "Correlation between Vehicle 1 and FAULT_SCORE: 0.433\n",
      "\n",
      "Trucking subset (MCARR_I1==57 & USDOT present): 13,712\n",
      "Unique DOTs in trucking subset: 10,725\n",
      "Census rows: 2,091,643\n",
      "Row-level match rate (after expansion by FARS vehicles): 0.5%\n",
      "Census rows with â‰¥1 FARS match: 0.4%\n",
      "\n",
      "Merged census (kept all rows): 2,094,364 total rows; unique DOTs: 2,091,643\n",
      "\n",
      "Saved Parquet files:\n",
      "  fars_scored.parquet\n",
      "  fars_trucking_usdot.parquet\n",
      "  census_with_fars.parquet\n"
     ]
    }
   ],
   "source": [
    "#Enter specific datasets here\n",
    "fars_files = [\n",
    "    (\"fars_2020_vehicle.csv\", 2020),\n",
    "    (\"fars_2021_vehicle.csv\", 2021),\n",
    "    (\"fars_2022_vehicle.csv\", 2022),\n",
    "    (\"fars_2023_vehicle.csv\", 2023)\n",
    "]\n",
    "\n",
    "census_csv = \"SMS_Input_-_Motor_Carrier_Census_Information_20250919.csv\"\n",
    "\n",
    "fars_scored, fars_trucking, fars_merged = run_fars_pipeline(fars_files, census_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
